"""Claude API í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ - ëª¨ë¸ í˜¼í•© ì‚¬ìš© + ê°•í™”ëœ ì—ëŸ¬ í•¸ë“¤ë§"""
import streamlit as st
from anthropic import Anthropic
import time
from functools import wraps


# ëª¨ë¸ ì„¤ì • (ìš©ë„ë³„ ìµœì í™”)
MODELS = {
    "opus": "claude-opus-4-20250514",      # ìµœê³  í’ˆì§ˆ (ì œëª©, ëª©ì°¨, íƒˆê³ )
    "sonnet": "claude-sonnet-4-20250514",  # ê³ í’ˆì§ˆ (ëŒ€í™”, í”¼ë“œë°±)
    "haiku": "claude-3-5-haiku-20241022",  # ë¹„ìš© ì ˆê° (ì´ˆì•ˆ ìƒì„±)
}

# ì—ëŸ¬ ë©”ì‹œì§€ (ì¹œê·¼í•œ í•œêµ­ì–´)
ERROR_MESSAGES = {
    "api_key": """
**API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì–´ìš”!**

ì„ ìƒë‹˜ê»˜ "API í‚¤ ì„¤ì •ì´ í•„ìš”í•´ìš”"ë¼ê³  ë§ì”€í•´ ì£¼ì„¸ìš”!
(ê¸°ìˆ  ì •ë³´: Streamlit Secretsì— ANTHROPIC_API_KEYë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤)
""",
    "network": """
**ì¸í„°ë„· ì—°ê²°ì´ ëŠê¸´ ê²ƒ ê°™ì•„ìš”!**

ì´ë ‡ê²Œ í•´ë´:
1. ì™€ì´íŒŒì´ë‚˜ ì¸í„°ë„· ì—°ê²° í™•ì¸í•˜ê¸°
2. ì ê¹ ê¸°ë‹¤ë ¸ë‹¤ê°€ ë‹¤ì‹œ ì‹œë„í•˜ê¸°
""",
    "rate_limit": """
**ë„ˆë¬´ ë§ì€ ìš”ì²­ì„ ë³´ëƒˆì–´ìš”!**

1ë¶„ë§Œ ì‰¬ì—ˆë‹¤ê°€ ë‹¤ì‹œ í•´ë³¼ê¹Œìš”?
(ë‹¤ë¥¸ ì‚¬ëŒë“¤ë„ AIë¥¼ ë§ì´ ì‚¬ìš©í•˜ê³  ìˆì–´ìš”)
""",
    "timeout": """
**ì‘ë‹µì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë ¤ìš”!**

AIê°€ ë°”ìœê°€ ë´ìš”. 30ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ë³¼ê¹Œìš”?
""",
    "server": """
**AI ì„œë²„ì— ë¬¸ì œê°€ ìƒê²¼ì–´ìš”!**

ì´ê±´ ìš°ë¦¬ ì˜ëª»ì´ ì•„ë‹ˆì—ìš”! ì ê¹ ê¸°ë‹¤ë ¸ë‹¤ê°€ ë‹¤ì‹œ í•´ë´ìš”.
""",
    "invalid_request": """
**ìš”ì²­ì— ë¬¸ì œê°€ ìˆì–´ìš”!**

ì…ë ¥ ë‚´ìš©ì„ í™•ì¸í•´ë³´ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
""",
    "content_policy": """
**ì…ë ¥ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”!**

AIê°€ ì²˜ë¦¬í•˜ê¸° ì–´ë ¤ìš´ ë‚´ìš©ì´ ìˆì„ ìˆ˜ ìˆì–´ìš”.
ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œí˜„í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?
""",
    "unknown": """
**ì•—! ë­”ê°€ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”!**

ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”! ì´ë ‡ê²Œ í•´ë´:
1. 30ì´ˆ ê¸°ë‹¤ë ¸ë‹¤ê°€ ë‹¤ì‹œ ì‹œë„í•˜ê¸°
2. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ë³´ê¸°
3. ë¬¸ì œê°€ ê³„ì†ë˜ë©´ ì„ ìƒë‹˜ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”!
"""
}

# ì¬ì‹œë„ ì„¤ì •
MAX_RETRIES = 3
RETRY_DELAY = 2  # ì´ˆ


def classify_error(error: Exception) -> str:
    """ì—ëŸ¬ ìœ í˜•ì„ ë¶„ë¥˜í•˜ì—¬ ì ì ˆí•œ ë©”ì‹œì§€ í‚¤ ë°˜í™˜"""
    error_str = str(error).lower()

    # ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì—ëŸ¬
    if any(keyword in error_str for keyword in ['connection', 'network', 'unreachable', 'dns', 'socket']):
        return "network"

    # íƒ€ì„ì•„ì›ƒ
    if any(keyword in error_str for keyword in ['timeout', 'timed out', 'time out']):
        return "timeout"

    # Rate limit
    if any(keyword in error_str for keyword in ['rate limit', 'rate_limit', '429', 'too many requests']):
        return "rate_limit"

    # ì„œë²„ ì—ëŸ¬
    if any(keyword in error_str for keyword in ['500', '502', '503', '504', 'server error', 'internal error']):
        return "server"

    # ì˜ëª»ëœ ìš”ì²­
    if any(keyword in error_str for keyword in ['400', 'bad request', 'invalid']):
        return "invalid_request"

    # ì½˜í…ì¸  ì •ì±…
    if any(keyword in error_str for keyword in ['content policy', 'blocked', 'moderation']):
        return "content_policy"

    # API í‚¤ ê´€ë ¨
    if any(keyword in error_str for keyword in ['401', 'unauthorized', 'authentication', 'api key', 'forbidden', '403']):
        return "api_key"

    return "unknown"


def with_retry(max_retries: int = MAX_RETRIES, delay: float = RETRY_DELAY):
    """API í˜¸ì¶œ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_error = None

            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_error = e
                    error_type = classify_error(e)

                    # ì¬ì‹œë„ê°€ ì˜ë¯¸ ì—†ëŠ” ì—ëŸ¬ëŠ” ë°”ë¡œ ë°˜í™˜
                    if error_type in ["api_key", "invalid_request", "content_policy"]:
                        raise e

                    # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ëŒ€ê¸° í›„ ì¬ì‹œë„
                    if attempt < max_retries - 1:
                        wait_time = delay * (attempt + 1)  # ì ì§„ì  ëŒ€ê¸°
                        time.sleep(wait_time)
                        continue
                    else:
                        raise e

            raise last_error
        return wrapper
    return decorator


def get_client():
    """Anthropic í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    try:
        api_key = st.secrets.get("ANTHROPIC_API_KEY")
        if not api_key or api_key == "ì—¬ê¸°ì—_API_í‚¤_ì…ë ¥":
            st.error(ERROR_MESSAGES["api_key"])
            return None
        return Anthropic(api_key=api_key)
    except Exception as e:
        st.error(ERROR_MESSAGES["api_key"])
        return None


def show_error_with_retry(error_type: str, show_retry_button: bool = True, key: str = None):
    """ì—ëŸ¬ ë©”ì‹œì§€ì™€ ì¬ì‹œë„ ë²„íŠ¼ í‘œì‹œ"""
    st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))

    if show_retry_button and key:
        if st.button("ğŸ”„ ë‹¤ì‹œ ì‹œë„í•˜ê¸°", key=f"retry_{key}"):
            st.rerun()


@with_retry()
def generate_response(prompt: str, system_prompt: str = None, max_tokens: int = 4096, model_type: str = "sonnet") -> str:
    """
    Claude APIë¥¼ í†µí•´ ì‘ë‹µ ìƒì„±

    Args:
        prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì„ íƒ)
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
        model_type: ëª¨ë¸ íƒ€ì… ("opus", "sonnet", "haiku")

    Returns:
        ìƒì„±ëœ ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    # ì…ë ¥ ê²€ì¦ - íƒ€ì… ì²´í¬ ì¶”ê°€
    if not prompt or not isinstance(prompt, str) or not prompt.strip():
        st.warning("ì…ë ¥ ë‚´ìš©ì´ ë¹„ì–´ìˆì–´ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
        return None

    # ë„ˆë¬´ ê¸´ ì…ë ¥ ì²˜ë¦¬
    MAX_INPUT_LENGTH = 100000  # ì•½ 100K ë¬¸ì
    if len(prompt) > MAX_INPUT_LENGTH:
        st.warning(f"ì…ë ¥ì´ ë„ˆë¬´ ê¸¸ì–´ìš”! {MAX_INPUT_LENGTH:,}ì ì´ë‚´ë¡œ ì¤„ì—¬ì£¼ì„¸ìš”. (í˜„ì¬: {len(prompt):,}ì)")
        prompt = prompt[:MAX_INPUT_LENGTH]

    client = get_client()
    # í´ë¼ì´ì–¸íŠ¸ None ì²´í¬ ì¶”ê°€
    if client is None:
        return None

    messages = [{"role": "user", "content": prompt}]

    try:
        kwargs = {
            "model": MODELS.get(model_type, MODELS["sonnet"]),
            "max_tokens": max_tokens,
            "messages": messages,
        }

        if system_prompt and isinstance(system_prompt, str):
            kwargs["system"] = system_prompt

        response = client.messages.create(**kwargs)

        # ì‘ë‹µ ê²€ì¦ ê°•í™”
        if not response or not response.content:
            st.warning("AIê°€ ë¹ˆ ì‘ë‹µì„ ë³´ëƒˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return None

        if len(response.content) == 0:
            st.warning("AIê°€ ë¹ˆ ì‘ë‹µì„ ë³´ëƒˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return None

        return response.content[0].text

    except Exception as e:
        error_type = classify_error(e)
        st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))

        # ë””ë²„ê¹…ìš© ìƒì„¸ ì •ë³´ (ê°œë°œììš©) - ì—ëŸ¬ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
        with st.expander("ê¸°ìˆ  ì •ë³´ (ì„ ìƒë‹˜ê»˜ ë³´ì—¬ì£¼ì„¸ìš”)", expanded=False):
            st.code(f"ì—ëŸ¬ ìœ í˜•: {error_type}\nì—ëŸ¬ ë‚´ìš©: {str(e)[:500]}")

        return None


# ============================================================
# ğŸ”´ OPUS ì‚¬ìš© (ìµœê³  í’ˆì§ˆ) - ì œëª©, ëª©ì°¨, íƒˆê³ , ê¸°íšì„œ
# ============================================================

def generate_titles(book_info: dict) -> str:
    """ì œëª© 10ê°œ ìƒì„± [OPUS]"""
    # ì…ë ¥ ê²€ì¦
    if not book_info:
        st.warning("ì±… ì •ë³´ê°€ ì—†ì–´ìš”. 1ë‹¨ê³„ì—ì„œ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None

    required_fields = ["topic", "target_reader", "core_message"]
    missing_fields = [f for f in required_fields if not book_info.get(f)]
    if missing_fields:
        st.warning(f"ë‹¤ìŒ ì •ë³´ê°€ í•„ìš”í•´ìš”: {', '.join(missing_fields)}")
        return None

    try:
        from prompts.templates import get_title_generation_prompt
        prompt = get_title_generation_prompt(book_info)
        system = "ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ í¸ì§‘ìì…ë‹ˆë‹¤. ë…ìì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ëŠ” ì œëª©ì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
        return generate_response(prompt, system, model_type="opus")
    except ImportError as e:
        st.error("í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì„ ìƒë‹˜ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”!")
        return None
    except Exception as e:
        error_type = classify_error(e)
        st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))
        return None


def generate_toc(book_info: dict) -> str:
    """ëª©ì°¨ 40ê¼­ì§€ ìƒì„± [OPUS]"""
    # ì…ë ¥ ê²€ì¦
    if not book_info:
        st.warning("ì±… ì •ë³´ê°€ ì—†ì–´ìš”. 1ë‹¨ê³„ì—ì„œ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None

    try:
        from prompts.templates import get_toc_generation_prompt
        prompt = get_toc_generation_prompt(book_info)
        system = "ë‹¹ì‹ ì€ 50ê¶Œ ì´ìƒ í¸ì§‘í•œ ë² í…Œë‘ ì¶œíŒ í¸ì§‘ìì…ë‹ˆë‹¤. ë…¼ë¦¬ì ì´ê³  ë§¤ë ¥ì ì¸ ì±… êµ¬ì¡°ë¥¼ ì„¤ê³„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
        return generate_response(prompt, system, model_type="opus")
    except ImportError as e:
        st.error("í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì„ ìƒë‹˜ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”!")
        return None
    except Exception as e:
        error_type = classify_error(e)
        st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))
        return None


def refine_text(text: str) -> str:
    """ë¬¸ì¥ ë‹¤ë“¬ê¸°/íƒˆê³  [OPUS]"""
    # ì…ë ¥ ê²€ì¦
    if not text or not text.strip():
        st.warning("ë‹¤ë“¬ì„ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì–´ìš”.")
        return None

    if len(text) < 10:
        st.warning("í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì•„ìš”. ì¡°ê¸ˆ ë” ì‘ì„±í•´ì£¼ì„¸ìš”.")
        return None

    try:
        from prompts.templates import get_refine_prompt
        prompt = get_refine_prompt(text)
        system = "ë‹¹ì‹ ì€ êµì—´ ì „ë¬¸ í¸ì§‘ìì…ë‹ˆë‹¤. ê¸€ì„ ë” ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰½ê²Œ ë‹¤ë“¬ìŠµë‹ˆë‹¤."
        return generate_response(prompt, system, model_type="opus")
    except ImportError as e:
        st.error("í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì„ ìƒë‹˜ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”!")
        return None
    except Exception as e:
        error_type = classify_error(e)
        st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))
        return None


def edit_draft_with_instruction(draft: str, instruction: str) -> str:
    """ì‚¬ìš©ì ì§€ì‹œì— ë”°ë¼ ì´ˆì•ˆ ìˆ˜ì • [OPUS]"""
    # ì…ë ¥ ê²€ì¦
    if not draft or not draft.strip():
        st.warning("ìˆ˜ì •í•  ì´ˆì•ˆì´ ë¹„ì–´ìˆì–´ìš”.")
        return None

    if not instruction or not instruction.strip():
        st.warning("ìˆ˜ì • ì§€ì‹œì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None

    if len(instruction) > 5000:
        st.warning("ìˆ˜ì • ì§€ì‹œì‚¬í•­ì´ ë„ˆë¬´ ê¸¸ì–´ìš”. 5000ì ì´ë‚´ë¡œ ì¤„ì—¬ì£¼ì„¸ìš”.")
        instruction = instruction[:5000]

    prompt = f"""ë‹¤ìŒ ì´ˆì•ˆì„ ì‚¬ìš©ìì˜ ì§€ì‹œì— ë”°ë¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

## ì›ë³¸ ì´ˆì•ˆ:
{draft}

## ìˆ˜ì • ì§€ì‹œì‚¬í•­:
{instruction}

## ìš”êµ¬ì‚¬í•­:
1. ì§€ì‹œì‚¬í•­ì— ë§ê²Œ ìˆ˜ì •
2. ì›ë³¸ì˜ ì „ì²´ì ì¸ í†¤ê³¼ ìŠ¤íƒ€ì¼ ìœ ì§€
3. ìˆ˜ì •ëœ ì „ì²´ ê¸€ì„ ì¶œë ¥
4. ìˆ˜ì •í•œ ë¶€ë¶„ì€ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ

ìˆ˜ì •ëœ ê¸€ì„ ë°”ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”."""

    system = "ë‹¹ì‹ ì€ ì „ë¬¸ í¸ì§‘ìì…ë‹ˆë‹¤. ì‘ê°€ì˜ ì˜ë„ë¥¼ ì‚´ë¦¬ë©´ì„œ ê¸€ì„ ìˆ˜ì •í•©ë‹ˆë‹¤."
    return generate_response(prompt, system, model_type="opus")


def generate_proposal(book_info: dict, author_info: dict) -> str:
    """ì¶œê°„ê¸°íšì„œ ìƒì„± [OPUS]"""
    # ì…ë ¥ ê²€ì¦
    if not book_info:
        st.warning("ì±… ì •ë³´ê°€ ì—†ì–´ìš”. 1ë‹¨ê³„ì—ì„œ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None

    if not author_info:
        st.warning("ì €ì ì •ë³´ê°€ ì—†ì–´ìš”. ì €ì ì •ë³´ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None

    try:
        from prompts.templates import get_proposal_generation_prompt
        prompt = get_proposal_generation_prompt(book_info, author_info)
        system = "ë‹¹ì‹ ì€ ëŒ€í˜• ì¶œíŒì‚¬ ê¸°íš í¸ì§‘ìì…ë‹ˆë‹¤. ë‹µì¥ë¥  85%ì˜ ê¸°íšì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
        return generate_response(prompt, system, model_type="opus")
    except ImportError as e:
        st.error("í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì„ ìƒë‹˜ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”!")
        return None
    except Exception as e:
        error_type = classify_error(e)
        st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))
        return None


def generate_landing_page(book_info: dict, webinar_info: dict) -> str:
    """ëœë”©í˜ì´ì§€ ì¹´í”¼ ìƒì„± [OPUS]"""
    # ì…ë ¥ ê²€ì¦
    if not book_info:
        st.warning("ì±… ì •ë³´ê°€ ì—†ì–´ìš”. 1ë‹¨ê³„ì—ì„œ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None

    if not webinar_info:
        st.warning("ì›¨ë¹„ë‚˜ ì •ë³´ê°€ ì—†ì–´ìš”. ì›¨ë¹„ë‚˜ ì •ë³´ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None

    try:
        from prompts.templates import get_landing_page_prompt
        prompt = get_landing_page_prompt(book_info, webinar_info)
        system = "ë‹¹ì‹ ì€ ì „í™˜ìœ¨ 30% ì´ìƒì˜ ëœë”©í˜ì´ì§€ ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤."
        return generate_response(prompt, system, model_type="opus")
    except ImportError as e:
        st.error("í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì„ ìƒë‹˜ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”!")
        return None
    except Exception as e:
        error_type = classify_error(e)
        st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))
        return None


# ============================================================
# ğŸŸ¢ HAIKU ì‚¬ìš© (ë¹„ìš© ì ˆê°) - ì´ˆì•ˆ ìƒì„±
# ============================================================

def generate_draft(book_info: dict, section_info: dict) -> str:
    """ê¼­ì§€ë³„ ì´ˆì•ˆ ìƒì„± 2000ì [HAIKU - ë¹„ìš© ì ˆê°]"""
    # ì…ë ¥ ê²€ì¦
    if not book_info:
        st.warning("ì±… ì •ë³´ê°€ ì—†ì–´ìš”.")
        return None

    if not section_info:
        st.warning("ì„¹ì…˜ ì •ë³´ê°€ ì—†ì–´ìš”.")
        return None

    try:
        from prompts.templates import get_draft_generation_prompt
        prompt = get_draft_generation_prompt(book_info, section_info)
        system = "ë‹¹ì‹ ì€ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì‘ê°€ì˜ ê³ ìŠ¤íŠ¸ë¼ì´í„°ì…ë‹ˆë‹¤. ë…ìê°€ ìˆ ìˆ  ì½íˆëŠ” ê¸€ì„ ì”ë‹ˆë‹¤."
        return generate_response(prompt, system, model_type="haiku")
    except ImportError as e:
        st.error("í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì„ ìƒë‹˜ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”!")
        return None
    except Exception as e:
        error_type = classify_error(e)
        st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))
        return None


def add_storytelling(experience: str) -> str:
    """ìŠ¤í† ë¦¬í…”ë§ ì¶”ê°€ [HAIKU - ë¹„ìš© ì ˆê°]"""
    # ì…ë ¥ ê²€ì¦
    if not experience or not experience.strip():
        st.warning("ìŠ¤í† ë¦¬í…”ë§í•  ê²½í—˜ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None

    if len(experience) < 20:
        st.warning("ê²½í—˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì•„ìš”. ì¡°ê¸ˆ ë” ìì„¸íˆ ì ì–´ì£¼ì„¸ìš”.")
        return None

    try:
        from prompts.templates import get_storytelling_prompt
        prompt = get_storytelling_prompt(experience)
        system = "ë‹¹ì‹ ì€ ìŠ¤í† ë¦¬í…”ë§ ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤. ë°‹ë°‹í•œ ê²½í—˜ì„ ê°ë™ì ì¸ ì´ì•¼ê¸°ë¡œ ë°”ê¿‰ë‹ˆë‹¤."
        return generate_response(prompt, system, model_type="haiku")
    except ImportError as e:
        st.error("í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì„ ìƒë‹˜ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”!")
        return None
    except Exception as e:
        error_type = classify_error(e)
        st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))
        return None


# ============================================================
# ğŸŸ¡ SONNET ì‚¬ìš© (ê· í˜•) - ëŒ€í™”, í”¼ë“œë°±
# ============================================================

def get_feedback(content: str, feedback_type: str) -> str:
    """í”¼ë“œë°± ìƒì„± (ì œëª©/ëª©ì°¨/ì›ê³ ) [SONNET]"""
    # ì…ë ¥ ê²€ì¦
    if not content or not content.strip():
        st.warning("í”¼ë“œë°±í•  ë‚´ìš©ì´ ë¹„ì–´ìˆì–´ìš”.")
        return None

    valid_types = ["title", "toc", "draft", "ì œëª©", "ëª©ì°¨", "ì›ê³ "]
    if feedback_type not in valid_types:
        st.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” í”¼ë“œë°± ìœ í˜•ì´ì—ìš”: {feedback_type}")
        return None

    try:
        from prompts.templates import get_feedback_prompt
        prompt = get_feedback_prompt(content, feedback_type)
        system = "ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ì¶œíŒ í¸ì§‘ìì…ë‹ˆë‹¤. ê±´ì„¤ì ì´ê³  êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."
        return generate_response(prompt, system, model_type="sonnet")
    except ImportError as e:
        st.error("í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì„ ìƒë‹˜ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”!")
        return None
    except Exception as e:
        error_type = classify_error(e)
        st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))
        return None


def chat_with_coach(messages: list, book_info: dict = None, elementary_friendly: bool = False) -> str:
    """ì±…ì“°ê¸° ì½”ì¹˜ì™€ ëŒ€í™” [SONNET]

    Args:
        messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        book_info: ì±… ì •ë³´ ë”•ì…”ë„ˆë¦¬
        elementary_friendly: Trueë©´ ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì‰½ê²Œ ë‹µë³€
    """
    # ì…ë ¥ ê²€ì¦
    if not messages:
        if not elementary_friendly:
            st.warning("ëŒ€í™” ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆì–´ìš”.")
        return None

    # ë©”ì‹œì§€ ê¸¸ì´ ê²€ì¦
    total_length = sum(len(str(m.get('content', ''))) for m in messages)
    MAX_CONVERSATION_LENGTH = 50000
    if total_length > MAX_CONVERSATION_LENGTH:
        # ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±°
        while total_length > MAX_CONVERSATION_LENGTH and len(messages) > 2:
            removed = messages.pop(0)
            total_length -= len(str(removed.get('content', '')))

    client = get_client()
    # í´ë¼ì´ì–¸íŠ¸ None ì²´í¬ ì¶”ê°€
    if client is None:
        return None

    if elementary_friendly:
        # ì´ˆë“±í•™ìƒ ì¹œí™”ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system = """ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±…ì“°ê¸° ë„ìš°ë¯¸ì˜ˆìš”.
ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ë‹µë³€ ê·œì¹™:
1. ì–´ë ¤ìš´ ë‹¨ì–´ ëŒ€ì‹  ì‰¬ìš´ ë‹¨ì–´ ì‚¬ìš©í•˜ê¸°
2. ì˜ˆì‹œë¥¼ ë§ì´ ë“¤ì–´ì£¼ê¸°
3. ê²©ë ¤ ë©”ì‹œì§€ ê¼­ í¬í•¨í•˜ê¸° (ì˜ˆ: "ì˜ í•˜ê³  ìˆì–´ìš”!", "í•  ìˆ˜ ìˆì–´ìš”!")
4. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ì„œ ì¹œê·¼í•˜ê²Œ
5. 2-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ê¸°
6. "~í•´ìš”", "~ì˜ˆìš”" ê°™ì€ ì¹œê·¼í•œ ë§íˆ¬ ì‚¬ìš©í•˜ê¸°

ê¸ˆì§€ ì‚¬í•­:
- ì–´ë ¤ìš´ ì „ë¬¸ ìš©ì–´ ì‚¬ìš©í•˜ì§€ ì•Šê¸°
- ë„ˆë¬´ ê¸´ ì„¤ëª… í•˜ì§€ ì•Šê¸°
- ë¹„íŒì ì´ê±°ë‚˜ ë¶€ì •ì ì¸ í‘œí˜„ í•˜ì§€ ì•Šê¸°"""
    else:
        system = """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ì±…ì“°ê¸° ì½”ì¹˜ì…ë‹ˆë‹¤.
ìˆ˜ê°•ìƒì´ ì±…ì„ ì™„ì„±í•  ìˆ˜ ìˆë„ë¡ ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë„ì™€ì¤ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì—­í• :
- ì±… ì£¼ì œ, ì œëª©, ëª©ì°¨ì— ëŒ€í•œ ì¡°ì–¸
- ê¸€ì“°ê¸° ë§‰í˜ í•´ê²°
- ì´ˆì•ˆ í”¼ë“œë°± ë° ìˆ˜ì • ì œì•ˆ
- ìŠ¤í† ë¦¬í…”ë§ ê¸°ë²• ì•ˆë‚´
- ë™ê¸°ë¶€ì—¬ ë° ê²©ë ¤

ë‹µë³€ ìŠ¤íƒ€ì¼:
- ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤
- êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì œê³µ
- ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸
- í•œêµ­ì–´ë¡œ ë‹µë³€"""

    if book_info:
        context = f"""

í˜„ì¬ ìˆ˜ê°•ìƒ ì •ë³´:
- ì´ë¦„: {book_info.get('name', 'ë¯¸ì…ë ¥')}
- ì±… ì£¼ì œ: {book_info.get('topic', 'ë¯¸ì…ë ¥')}
- íƒ€ê²Ÿ ë…ì: {book_info.get('target_reader', 'ë¯¸ì…ë ¥')}
- í•µì‹¬ ë©”ì‹œì§€: {book_info.get('core_message', 'ë¯¸ì…ë ¥')}
- ì„ íƒí•œ ì œëª©: {book_info.get('title', 'ë¯¸ì„ íƒ')}
"""
        system += context

    try:
        response = client.messages.create(
            model=MODELS["sonnet"],
            max_tokens=1024 if elementary_friendly else 2048,
            system=system,
            messages=messages,
        )

        if not response or not response.content:
            if not elementary_friendly:
                st.warning("AIê°€ ì‘ë‹µí•˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return None

        return response.content[0].text

    except Exception as e:
        error_type = classify_error(e)
        if not elementary_friendly:
            st.error(ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"]))
        return None


# ============================================================
# ìœ íŠœë¸Œ ëª¨ë“œ ì „ìš© í•¨ìˆ˜ë“¤
# ============================================================

def analyze_youtube_transcript(transcript: str, video_title: str = "") -> str:
    """ìœ íŠœë¸Œ ìë§‰ ë¶„ì„ ë° í•µì‹¬ ë‚´ìš© ì¶”ì¶œ [SONNET]"""
    # ì…ë ¥ ê²€ì¦
    if not transcript or not transcript.strip():
        st.warning("ë¶„ì„í•  ìë§‰ì´ ë¹„ì–´ìˆì–´ìš”.")
        return None

    if len(transcript) < 100:
        st.warning("ìë§‰ì´ ë„ˆë¬´ ì§§ì•„ìš”. ë” ê¸´ ì˜ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return None

    # ìë§‰ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
    MAX_TRANSCRIPT_LENGTH = 15000
    if len(transcript) > MAX_TRANSCRIPT_LENGTH:
        transcript = transcript[:MAX_TRANSCRIPT_LENGTH]

    prompt = f"""ë‹¤ìŒì€ ìœ íŠœë¸Œ ì˜ìƒì˜ ìë§‰ì…ë‹ˆë‹¤.

## ì˜ìƒ ì œëª©: {video_title}

## ìë§‰ ë‚´ìš©:
{transcript[:8000]}

## ë¶„ì„ ìš”ì²­:
1. **í•µì‹¬ ì£¼ì œ**: ì´ ì˜ìƒì´ ë‹¤ë£¨ëŠ” í•µì‹¬ ì£¼ì œ (1-2ë¬¸ì¥)
2. **ì£¼ìš” ë‚´ìš©**: ì˜ìƒì—ì„œ ë‹¤ë£¨ëŠ” ì£¼ìš” í¬ì¸íŠ¸ 5-7ê°œ (ë¶ˆë¦¿ í¬ì¸íŠ¸)
3. **íƒ€ê²Ÿ ë…ì**: ì´ ë‚´ìš©ì„ ì±…ìœ¼ë¡œ ë§Œë“¤ë©´ ëˆ„ê°€ ì½ìœ¼ë©´ ì¢‹ì„ì§€
4. **í•µì‹¬ ë©”ì‹œì§€**: í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ëœ í•µì‹¬ ë©”ì‹œì§€
5. **ì±… ì œëª© ì œì•ˆ**: ì´ ë‚´ìš©ìœ¼ë¡œ ì±…ì„ ë§Œë“¤ ë•Œ ì–´ìš¸ë¦¬ëŠ” ì œëª© 3ê°œ

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”."""

    system = "ë‹¹ì‹ ì€ ì½˜í…ì¸  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì˜ìƒ ë‚´ìš©ì„ ì±…ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
    return generate_response(prompt, system, max_tokens=2048, model_type="sonnet")


def generate_titles_from_transcript(transcript: str, video_info: dict) -> str:
    """ìœ íŠœë¸Œ ìë§‰ ê¸°ë°˜ ì œëª© ìƒì„± [OPUS]"""
    # ì…ë ¥ ê²€ì¦
    if not transcript or not transcript.strip():
        st.warning("ìë§‰ì´ ë¹„ì–´ìˆì–´ìš”.")
        return None

    if not video_info:
        st.warning("ì˜ìƒ ì •ë³´ê°€ ì—†ì–´ìš”.")
        return None

    try:
        from prompts.templates import TITLE_FORMULAS
    except ImportError:
        TITLE_FORMULAS = ""

    prompt = f"""ìœ íŠœë¸Œ ì˜ìƒ ì •ë³´:
- ì œëª©: {video_info.get('title', '')}
- ì±„ë„: {video_info.get('channel', '')}

ìë§‰ ë‚´ìš© ìš”ì•½:
{transcript[:6000]}

{TITLE_FORMULAS}

ìœ„ ì œëª© ê³µì‹ 10ê°€ì§€ë¥¼ ê°ê° ì ìš©í•´ì„œ ì´ ì˜ìƒ ë‚´ìš©ìœ¼ë¡œ ì±… ì œëª© 10ê°œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ê° ì œëª©ì— ëŒ€í•´:
1. ì ìš©í•œ ê³µì‹ ë²ˆí˜¸ì™€ ì´ë¦„
2. ì œëª©
3. ì´ ì œëª©ì˜ ì¥ì  (í•œ ì¤„)
4. ë¶€ì œëª© ì œì•ˆ (ì„ íƒ)

í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”."""

    system = "ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ í¸ì§‘ìì…ë‹ˆë‹¤. ìœ íŠœë¸Œ ì½˜í…ì¸ ë¥¼ ë§¤ë ¥ì ì¸ ì±… ì œëª©ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
    return generate_response(prompt, system, model_type="opus")


def generate_toc_from_transcript(transcript: str, book_info: dict, video_count: int = 1) -> str:
    """ìœ íŠœë¸Œ ìë§‰ ê¸°ë°˜ ëª©ì°¨ ìƒì„± [OPUS]"""
    # ì…ë ¥ ê²€ì¦
    if not transcript or not transcript.strip():
        st.warning("ìë§‰ì´ ë¹„ì–´ìˆì–´ìš”.")
        return None

    if not book_info:
        st.warning("ì±… ì •ë³´ê°€ ì—†ì–´ìš”.")
        return None

    if video_count > 1:
        structure_guide = f"""
## êµ¬ì¡° ì•ˆë‚´:
- ì´ {video_count}ê°œ ì˜ìƒì˜ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤
- ê° ì˜ìƒì„ í•˜ë‚˜ì˜ Partë¡œ êµ¬ì„±í•˜ë˜, ë…¼ë¦¬ì ìœ¼ë¡œ ì¬ë°°ì—´í•´ë„ ë©ë‹ˆë‹¤
- 5ë¶€ 40ê¼­ì§€ êµ¬ì¡°ë¡œ í†µí•©í•˜ì„¸ìš”
"""
    else:
        structure_guide = """
## êµ¬ì¡° ì•ˆë‚´:
- 5ë¶€ 40ê¼­ì§€ êµ¬ì¡°ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”
- ê° PartëŠ” 8ê°œ ê¼­ì§€
"""

    prompt = f"""ë‚´ ì±… ì •ë³´:
- ì œëª©: {book_info.get('title', '')}
- íƒ€ê²Ÿ ë…ì: {book_info.get('target_reader', '')}
- í•µì‹¬ ë©”ì‹œì§€: {book_info.get('core_message', '')}

## ìœ íŠœë¸Œ ì˜ìƒ ìë§‰ ë‚´ìš©:
{transcript[:10000]}

{structure_guide}

## 5ë¶€ êµ¬ì¡° ì„¤ëª…:
- Part 1. WHY (ì™œ?): ë¬¸ì œ ì¸ì‹ & ë™ê¸° ë¶€ì—¬ - ë…ìê°€ "ì´ ì±… ê¼­ ì½ì–´ì•¼ê² ë‹¤"ê³  ëŠë¼ê²Œ
- Part 2. WHAT (ë¬´ì—‡?): í•µì‹¬ ê°œë… & ì›ë¦¬ - ê¸°ë³¸ ê°œë…ì„ ì™„ë²½íˆ ì´í•´í•˜ê²Œ
- Part 3. HOW (ì–´ë–»ê²Œ?): êµ¬ì²´ì  ë°©ë²•ë¡  - "ë‚˜ë„ í•  ìˆ˜ ìˆê² ë‹¤"ëŠ” ìì‹ ê°
- Part 4. DO (ì‹¤í–‰): ì‹¤ì „ ì ìš© & ì‚¬ë¡€ - ì‹¤ì œë¡œ ë”°ë¼í•˜ë©° ê²°ê³¼ë¬¼
- Part 5. FUTURE (ë¯¸ë˜): ë¹„ì „ & ë‹¤ìŒ ë‹¨ê³„ - ì±…ì„ ë®ì–´ë„ í–‰ë™í•˜ê²Œ

## ìš”êµ¬ì‚¬í•­:
1. ê° PartëŠ” 8ê°œ ê¼­ì§€
2. ì´ 40ê°œ ê¼­ì§€
3. ê° ê¼­ì§€ëŠ” ë¬¸ì¥í˜• ì œëª© (í˜¸ê¸°ì‹¬ ìœ ë°œ)
4. ì˜ìƒ ë‚´ìš©ì„ ì¶©ì‹¤íˆ ë°˜ì˜
5. ë…¼ë¦¬ì  íë¦„ ìœ ì§€
6. ë…ìê°€ ì½ê³  ì‹¶ì–´ì§€ëŠ” ì œëª©

## ì¶œë ¥ í˜•ì‹:
```
Part 1. [Part ì œëª©] - WHY (ì™œ?)
  1-1. [ê¼­ì§€ ì œëª©]
  1-2. [ê¼­ì§€ ì œëª©]
  ...

Part 2. [Part ì œëª©] - WHAT (ë¬´ì—‡?)
  2-1. [ê¼­ì§€ ì œëª©]
  ...
```"""

    system = "ë‹¹ì‹ ì€ 50ê¶Œ ì´ìƒ í¸ì§‘í•œ ë² í…Œë‘ ì¶œíŒ í¸ì§‘ìì…ë‹ˆë‹¤. ìœ íŠœë¸Œ ì½˜í…ì¸ ë¥¼ ì²´ê³„ì ì¸ ì±… êµ¬ì¡°ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
    return generate_response(prompt, system, model_type="opus")


def generate_draft_from_transcript(book_info: dict, section_info: dict, transcript_chunk: str) -> str:
    """ìœ íŠœë¸Œ ìë§‰ ê¸°ë°˜ ì´ˆì•ˆ ìƒì„± [HAIKU - ë¹„ìš© ì ˆê°]"""
    # ì…ë ¥ ê²€ì¦
    if not book_info:
        st.warning("ì±… ì •ë³´ê°€ ì—†ì–´ìš”.")
        return None

    if not section_info:
        st.warning("ì„¹ì…˜ ì •ë³´ê°€ ì—†ì–´ìš”.")
        return None

    if not transcript_chunk:
        st.warning("ìë§‰ ë‚´ìš©ì´ ì—†ì–´ìš”.")
        return None

    # ê¼­ì§€ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ê´€ë ¨ ìë§‰ ë¶€ë¶„ ì°¾ê¸°
    section_title = section_info.get('section_title', '')
    relevant_chunk = find_relevant_transcript_chunk(transcript_chunk, section_title)

    prompt = f"""ë‚´ ì±… ì •ë³´:
- ì œëª©: {book_info.get('title', '')}
- íƒ€ê²Ÿ ë…ì: {book_info.get('target_reader', '')}
- ì´ ì±…ì˜ í†¤: {book_info.get('tone', 'ì¹œê·¼í•œ')}

ì§€ê¸ˆ ì“¸ ê¼­ì§€:
- Part {section_info.get('part_number', '')}: {section_info.get('part_title', '')}
- ê¼­ì§€ ë²ˆí˜¸: {section_info.get('section_number', '')}
- ê¼­ì§€ ì œëª©: {section_info.get('section_title', '')}

## ì°¸ê³ í•  ìœ íŠœë¸Œ ìë§‰ ë‚´ìš©:
{relevant_chunk[:4000]}

## ìš”êµ¬ì‚¬í•­:
1. ë¶„ëŸ‰: 2000ì (ê³µë°± í¬í•¨)
2. ìë§‰ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•˜ë˜, ì±…ë‹¤ìš´ ë¬¸ì²´ë¡œ ì¬êµ¬ì„±
3. **êµ¬ì–´ì²´ â†’ ë¬¸ì–´ì²´ ë³€í™˜ ê·œì¹™**:
   - "~ê±°ë“ ìš”" â†’ "~ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤"
   - "~ì–ì•„ìš”" â†’ "~ì…ë‹ˆë‹¤"
   - "ê·¸ë˜ê°€ì§€ê³ " â†’ "ê·¸ë˜ì„œ"
   - "ì§„ì§œ", "ë§‰" â†’ ì‚­ì œ ë˜ëŠ” ì ì ˆí•œ í‘œí˜„ìœ¼ë¡œ
   - "~í•´ë³´ë‹ˆê¹Œ" â†’ "~í•´ë³¸ ê²°ê³¼"
   - "ì–´ ê·¸ëŸ¬ë‹ˆê¹Œ" ë“± ë§ ë”ë“¬ê¸° â†’ ì‚­ì œ
4. êµ¬ì¡°:
   - ë„ì… (í˜¸ê¸°ì‹¬ ìœ ë°œ, ì•½ 300ì)
   - ë³¸ë¡  (í•µì‹¬ ë‚´ìš© 3ê°€ì§€, ê° ì•½ 400ì)
   - ì‚¬ë¡€/ë°ì´í„° (ì„¤ë“ë ¥, ì•½ 400ì)
   - ë§ˆë¬´ë¦¬ (í–‰ë™ ìœ ë„, ì•½ 300ì)
5. ë¬¸ì¥ì€ ì§§ê²Œ (í•œ ë¬¸ì¥ 40ì ì´ë‚´)
6. í•œ ë¬¸ë‹¨ì€ 3-4ë¬¸ì¥
7. ì¤‘ê°„ì¤‘ê°„ ì†Œì œëª© ì‚¬ìš©
8. ë…ìì—ê²Œ ë§í•˜ë“¯ (~í•˜ì„¸ìš”, ~ì…ë‹ˆë‹¤)

ë°”ë¡œ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    system = "ë‹¹ì‹ ì€ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì‘ê°€ì˜ ê³ ìŠ¤íŠ¸ë¼ì´í„°ì…ë‹ˆë‹¤. ìœ íŠœë¸Œ ì½˜í…ì¸ ë¥¼ ì±…ë‹¤ìš´ ê¸€ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. êµ¬ì–´ì²´ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì–´ì²´ë¡œ ë°”ê¾¸ëŠ” ë° ëŠ¥ìˆ™í•©ë‹ˆë‹¤."
    return generate_response(prompt, system, model_type="haiku")


def find_relevant_transcript_chunk(transcript: str, section_title: str, chunk_size: int = 4000) -> str:
    """
    ì„¹ì…˜ ì œëª©ê³¼ ê´€ë ¨ëœ ìë§‰ ë¶€ë¶„ì„ ì°¾ì•„ ë°˜í™˜

    Args:
        transcript: ì „ì²´ ìë§‰
        section_title: ê¼­ì§€ ì œëª©
        chunk_size: ë°˜í™˜í•  ì²­í¬ í¬ê¸°

    Returns:
        ê´€ë ¨ ìë§‰ ë¶€ë¶„
    """
    if not transcript or not section_title:
        return transcript[:chunk_size] if transcript else ""

    # ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ ë‹¨ì–´)
    import re
    keywords = [word for word in re.findall(r'[ê°€-í£a-zA-Z]{2,}', section_title)]

    if not keywords:
        return transcript[:chunk_size]

    # ê° í‚¤ì›Œë“œê°€ ë“±ì¥í•˜ëŠ” ìœ„ì¹˜ ì°¾ê¸°
    positions = []
    for keyword in keywords[:3]:  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
        for match in re.finditer(re.escape(keyword), transcript, re.IGNORECASE):
            positions.append(match.start())

    if not positions:
        # í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ì „ì²´ ìë§‰ì„ ê· ë“±í•˜ê²Œ ë¶„í• 
        return transcript[:chunk_size]

    # ê°€ì¥ ë§ì€ í‚¤ì›Œë“œê°€ ë°€ì§‘ëœ êµ¬ê°„ ì°¾ê¸°
    avg_position = sum(positions) // len(positions)

    # í•´ë‹¹ ìœ„ì¹˜ ì¤‘ì‹¬ìœ¼ë¡œ ì²­í¬ ì¶”ì¶œ
    start = max(0, avg_position - chunk_size // 2)
    end = min(len(transcript), start + chunk_size)

    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸° (ë§ˆì¹¨í‘œ ê¸°ì¤€)
    chunk = transcript[start:end]

    # ì‹œì‘ ë¶€ë¶„ ì •ë¦¬ (ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ì‹œì‘í•˜ì§€ ì•Šë„ë¡)
    if start > 0:
        first_period = chunk.find('. ')
        if first_period != -1 and first_period < 100:
            chunk = chunk[first_period + 2:]

    return chunk
